{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sect 24 (v2.1): Regularization\n",
    "\n",
    "- online-ds-pt-100719\n",
    "- 03/19/2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCUSSION:**\n",
    "- Discuss Regularization Techniques\n",
    "    - Ridge Regression (L2 normalization)\n",
    "    - Lasso Regression (L1 normalization)\n",
    "- AIC/BIC\n",
    "- Compare Feature Selection methods\n",
    "\n",
    "**APPLICATION:**\n",
    "- Practice turning repetitive code into flexible functions/loops\n",
    "\n",
    "- Lab Walkthrough (pick one):\n",
    "    - [Sect 24: Ridge and Lasso Regression Lab](https://learn.co/tracks/data-science-career-v2/module-4-a-complete-data-science-project-using-multiple-regression/section-28-section-recap/ridge-and-lasso-regression-lab)\n",
    "    \n",
    "    - [Sect 24: Extensions to Linear Models Lab](https://learn.co/tracks/data-science-career-v2/module-4-a-complete-data-science-project-using-multiple-regression/section-28-section-recap/extensions-to-linear-models-lab)\n",
    "    \n",
    "- Alternative:\n",
    "    - Walk through feature selection lesson, but re-write so that all of the results for each method are collected into one table for us to review together.\n",
    "    - [Sect 24: Feature Selection](https://learn.co/tracks/data-science-career-v2/module-4-a-complete-data-science-project-using-multiple-regression/section-28-section-recap/feature-selection-methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:33.988907Z",
     "start_time": "2020-03-19T22:26:28.726185Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U fsds_100719\n",
    "from fsds_100719.imports import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can \"shrink down\" prediction variables effects instead of deleting/zeroing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalized Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***You've seen that when the number of predictors increases, your model complexity increases, with a higher chance of overfitting as a result.***  \n",
    "\n",
    "> Now, instead of completely \"deleting\" certain predictors from a model (which is equal to setting coefficients equal to zero) we can reduce the values of the coefficients to make them less sensitive to noise in the data. \n",
    "\n",
    "> This is called **penalized estimation**.\n",
    "\n",
    "> **Ridge and Lasso regression** are two examples of penalized estimation.<br>There are multiple advantages to using these methods:\n",
    "- They reduce model complexity\n",
    "- The may prevent from overfitting\n",
    "- Some of them may perform variable selection at the same time (when coefficients are set to 0)\n",
    "- They can be used to counter multicollinearity\n",
    "\n",
    "> Lasso and Ridge are two commonly used so-called **regularization techniques**. (Regularization is a general term used when one tries to battle overfitting.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Cost Function Previously Used (RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### For a single predictor (X)\n",
    "$$ \\large \\text{cost_function}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - (mx_i + b))^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###  multiple predictors, the equation becomes:\n",
    "$$ \\large \\text{cost_function}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij} ) -b )^2$$\n",
    "- where $k$ is the number of predictors\n",
    "- and $j$ is each individual predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression - L2 Norm Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a penalty ***hyperparameter*** $\\lambda$ for extra terms (large $m$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- $$ =\\sum_{i=1}^n(y_i - \\hat{y})^2= \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij} + b))^2 + \\lambda \\sum_{i=1}^n m_i^2$$/-->\n",
    "\n",
    "$$\\large J_{\\text{ridge}}=\\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij})-b)^2 + \\lambda \\sum_{j=1}^p m_j^2$$\n",
    "\n",
    "- **By adding the penalty term $\\lambda$, ridge regression puts a constraint on the coefficients $m$.**\n",
    "- Therefore, large coefficients will penalize the optimization function. \n",
    "    - This shrinks the coefficients and helps to reduce model complexity and multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Error term added to cost function** \n",
    "    - $\\large ...  +   \\lambda \\sum_{i=1}^n m_i^2$\n",
    "    - Notice that  $m_i^2$ is squared, hence \"L***2*** norm regularization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With two predictors there is a penalty term m for each predictor.\n",
    "$$\\large J_\\text{ridge}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = $$\n",
    "\n",
    "$$\\large  \\sum_{i=1}^n(y_i - ((m_1x_{1i})-b)^2 + \\lambda m_1^2 + (m_2x_{2i})-b)^2 + \\lambda m_2^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used mostly to prevent overfitting (but since includes all features it can be computationally expensive (for many variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression - L1 Norm Regularization\n",
    "\n",
    "\"Least Absolute Shrinkage and Selection Operator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large J_\\text{lasso}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij})-b)^2 + \\lambda \\sum_{j=1}^p \\mid m_j \\mid$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Error term added to cost function** \n",
    "    - $ \\large ... + \\lambda \\sum_{j=1}^p \\mid m_j \\mid$\n",
    "    - Notice that  $m$ has no exponent (meaning its actually $m^1$, hence \"L***1*** norm regularization\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have two predictors the full equation would look like this (notice that there is a penalty term `m` for each predictor in the model - in this case, two): \n",
    "$$ \\text{cost_function_lasso}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = $$\n",
    "\n",
    "$$\\sum_{i=1}^n(y_i - ((m_1x_{1i})-b)^2 + \\lambda \\mid m_1 \\mid) + ((m_2x_{2i})-b)^2 + \\lambda \\mid m_2 \\mid) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso also helps with over fitting \n",
    "- **Lasso shrinks the less important features' coefficients to zero**, removing them altogether. \n",
    "    - Therefore, Lasso regression can be used for **feature selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Make sure to standardize the data before performing ridge or lasso regression***, otherwise features with large values/units will be unfairly penalized.\n",
    "- **Fit-transform the training data, only transform the test data**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge & Lasson Regression Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Ridge regression, the cost function is changed by adding a penalty term to the square of the magnitude of the coefficients.\n",
    "\n",
    "$$ \\text{cost_function_ridge}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij})-b)^2 + \\lambda \\sum_{j=1}^p m_j^2$$\n",
    "\n",
    "Lasso regression is very similar to Ridge regression, except that the magnitude of the coefficients are not squared in the penalty term.\n",
    "\n",
    "$$ \\text{cost_function_lasso}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij})-b)^2 + \\lambda \\sum_{j=1}^p \\mid m_j \\mid$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Ridge and Lasso Regression with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.310658Z",
     "start_time": "2020-03-19T22:26:33.990528Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Load the data\n",
    "df = fs.datasets.load_autompg()\n",
    "\n",
    "y = df[['mpg']]\n",
    "X = df.drop(['mpg', 'car name', 'origin'], axis=1)\n",
    "\n",
    "# Perform test train split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                     random_state=12)\n",
    "[var.shape for var in [X_train , X_test, y_train, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.316935Z",
     "start_time": "2020-03-19T22:26:34.312137Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "X_train_transformed = scale.fit_transform(X_train)\n",
    "X_test_transformed = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhibit A: The case for functions and dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code From [Ridge And Lasso Regression Lesson](https://learn.co/tracks/module-3-data-science-career-2-1/machine-learning/section-24-feature-selection-ridge-and-lasso/ridge-and-lasso-regression)\n",
    "\n",
    "- The following code is from the Learn.co lesson and its goal is to create,fit and evaluate 3 different models to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.616677Z",
     "start_time": "2020-03-19T22:26:34.318259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build a Ridge, Lasso and regular linear regression model  \n",
    "# Note that in scikit-learn, the regularization parameter is denoted by alpha (and not lambda)\n",
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(X_train_transformed, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=0.5)\n",
    "lasso.fit(X_train_transformed, y_train)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train_transformed, y_train)\n",
    "\n",
    "\n",
    "# Generate preditions for training and test sets\n",
    "y_h_ridge_train = ridge.predict(X_train_transformed)\n",
    "y_h_ridge_test = ridge.predict(X_test_transformed)\n",
    "\n",
    "y_h_lasso_train = np.reshape(lasso.predict(X_train_transformed), (274, 1))\n",
    "y_h_lasso_test = np.reshape(lasso.predict(X_test_transformed), (118, 1))\n",
    "\n",
    "y_h_lin_train = lin.predict(X_train_transformed)\n",
    "y_h_lin_test = lin.predict(X_test_transformed)\n",
    "\n",
    "\n",
    "print('Train Error Ridge Model', np.sum((y_train - y_h_ridge_train)**2))\n",
    "print('Test Error Ridge Model', np.sum((y_test - y_h_ridge_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Lasso Model', np.sum((y_train - y_h_lasso_train)**2))\n",
    "print('Test Error Lasso Model', np.sum((y_test - y_h_lasso_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Unpenalized Linear Model', np.sum((y_train - lin.predict(X_train_transformed))**2))\n",
    "print('Test Error Unpenalized Linear Model', np.sum((y_test - lin.predict(X_test_transformed))**2))\n",
    "print('\\n'*3)\n",
    "print('Ridge parameter coefficients:\\n', ridge.coef_)\n",
    "print('Lasso parameter coefficients:\\n', lasso.coef_)\n",
    "print('Linear model parameter coefficients:\\n', lin.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: What are the issues/limitations of the way we tested/compared the 3 different types of models? \n",
    "-  A: \n",
    "\n",
    "### Q2: What other limitation does the above code have? (what is inflexible?)\n",
    "\n",
    "- A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whats the solution? \n",
    "- Functions and dictionaries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.621388Z",
     "start_time": "2020-03-19T22:26:34.618130Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def make_model():\n",
    "    \"\"\"Takes a sklearn model and train/test data to fit model, \n",
    "    get R2 and MSE for both the training and test data.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: results as a df\n",
    "        model: fit scikit-learn model itself\"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.636352Z",
     "start_time": "2020-03-19T22:26:34.630810Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use a dictionary to store our models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.655051Z",
     "start_time": "2020-03-19T22:26:34.638825Z"
    }
   },
   "outputs": [],
   "source": [
    "## Test our dictionary and function together to make a linear regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.716177Z",
     "start_time": "2020-03-19T22:26:34.656747Z"
    }
   },
   "outputs": [],
   "source": [
    "## Loop through models_to_make and save all results\n",
    "\n",
    "## Create an empty list to store result dfs\n",
    "\n",
    "## Create an empty dict to store fit models\n",
    "\n",
    "for model_type,mod in models_to_make.items():\n",
    "    pass\n",
    "\n",
    "    ## get model results and fit model using make_model\n",
    "    \n",
    "    ## Add model type as column to res\n",
    "    \n",
    "    # Display results\n",
    "    \n",
    "    ## Save fit model to models dict \n",
    "    \n",
    "    ## Save df to list \n",
    "\n",
    "## Concatenate results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.741563Z",
     "start_time": "2020-03-19T22:26:34.717706Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use styling to make it easier to find the best scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:34:40.925952Z",
     "start_time": "2020-03-19T22:34:40.855432Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now examine the coefficients of one of the fit models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Sidebar: You've heard of List Comprehensions but did you that there are Dictionary Comprehensions too?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.752258Z",
     "start_time": "2020-03-19T22:26:34.747780Z"
    }
   },
   "outputs": [],
   "source": [
    "## Get the coefficients of every model in a dictionary using a dict comprehension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:35:49.419478Z",
     "start_time": "2020-03-19T22:35:49.416761Z"
    }
   },
   "outputs": [],
   "source": [
    "## Notice the shapes of the arrays are not the same\n",
    "# Print out the shapes of each dict value\n",
    "\n",
    "## Try making it a dataframe (error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The solution: `.flatten()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.769762Z",
     "start_time": "2020-03-19T22:26:34.759710Z"
    }
   },
   "outputs": [],
   "source": [
    "## Use .flatten() to make coefs 1D\n",
    "\n",
    "## Notice the shapes of the arrays are not the same\n",
    "\n",
    "\n",
    "## make it into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:36:37.431166Z",
     "start_time": "2020-03-19T22:36:37.429050Z"
    }
   },
   "outputs": [],
   "source": [
    "### Put it all together  into 1 line of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:36:37.716456Z",
     "start_time": "2020-03-19T22:36:37.714321Z"
    }
   },
   "outputs": [],
   "source": [
    "## Tanspose df and round\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: what was the result of the different regressions on the coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uses of AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performing feature selection: comparing models with only a few variables and more variables, computing the AIC/BIC and select the features that generated the lowest AIC or BIC\n",
    "- Similarly, selecting or not selecting interactions/polynomial features depending on whether or not the AIC/BIC decreases when adding them in\n",
    "- Computing the AIC and BIC for several values of the regularization parameter in Ridge/Lasso models and selecting the best regularization parameter, and many more! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Akaike's Information Criterion (AIC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for the AIC, invented by Hirotugu Akaike in 1973 and short for \"Akaike's Information Criterion\" is given by:\n",
    "\n",
    "$$ \\large \\text{AIC} = -2\\ln(\\hat{L}) + 2k $$\n",
    "\n",
    "Where:\n",
    "* $k$ : length of the parameter space (i.e. the number of features)\n",
    "* $\\hat{L}$ : the maximum value of the likelihood function for the model\n",
    "\n",
    "Another way to phrase the equation is:\n",
    "\n",
    "$$ \n",
    "\\large \\text{AIC(model)} =  - 2 * \\text{log-likelihood(model)} + 2 * \\text{length of the parameter space} $$\n",
    "\n",
    "\n",
    "- AIC used to **compare** models with unbounded units not independently interpretable\n",
    "\n",
    "- If model uses Maximum Likelihood Estimation, log-likelihood is automatically computed, so AIC is easy to calculate.\n",
    "- AIC acts like penalized log-likelihood criterion, balancing good fit and complexity\n",
    "\n",
    "- In Python, the AIC is built into `statsmodels` and in `sklearn` (such as `LassoLarsIC`, which you'll use in the upcoming lab). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Information Criterion (BIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bayesian alternative to AIC, used the same way.\n",
    "\n",
    " $$\\large \\text{BIC} = -2\\ln(\\hat L) + \\ln(n)*k $$\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "* $\\hat{L}$ and $k$ are the same as in AIC\n",
    "* $n$ : the number of data points (the sample size)\n",
    "\n",
    "Another way to phrase the equation is:\n",
    "\n",
    "$$ \\text{BIC(model)} = -2 * \\text{log-likelihood(model)} + \\text{log(number of observations)} * \\text{(length of the parameter space)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.813271Z",
     "start_time": "2020-03-19T22:26:34.799711Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
    "alphas = np.arange(0.1,100,0.1)\n",
    "\n",
    "lasso_cvA = LassoLarsIC(criterion='aic')\n",
    "lasso_cvA.fit(X_train,y_train);\n",
    "lasso_cvA.alpha_\n",
    "\n",
    "\n",
    "lasso_cvB = LassoLarsIC(criterion='bic')\n",
    "lasso_cvB.fit(X_train,y_train);\n",
    "lasso_cvB.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:34.988976Z",
     "start_time": "2020-03-19T22:26:34.814698Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_ic_criterion(model, name, color):\n",
    "    \"\"\"Taken from:\n",
    "    https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html\"\"\"\n",
    "    # This is to avoid division by zero while doing np.log10\n",
    "    EPSILON = 1e-4\n",
    "    alpha_ = model.alpha_ + EPSILON\n",
    "    alphas_ = model.alphas_ + EPSILON\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n",
    "             linewidth=3, label='%s criterion' % name)\n",
    "    \n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=3,\n",
    "                label=f'alpha: {name} estimate (alpha={round(alpha_,5)})')\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plot_ic_criterion(lasso_cvA,'AIC','blue')\n",
    "plot_ic_criterion(lasso_cvB,'BIC','green')#,'BIC' )\n",
    "plt.legend(bbox_to_anchor=[1,1],loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "[Lesson](https://learn.co/tracks/module-3-data-science-career-2-1/machine-learning/section-24-feature-selection-ridge-and-lasso/feature-selection-methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Domain knowledge\n",
    "* Wrapper methods\n",
    "* Filter methods\n",
    "* Embedded methods\n",
    "\n",
    "> ### Wrapper Methods\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-feature-selection-methods-online-ds-pt-100719/master/images/new_wrapper.png\">\n",
    "\n",
    "\n",
    "> ### Filter Methods\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-feature-selection-methods-online-ds-pt-100719/master/images/new_filter.png\">\n",
    "\n",
    "\n",
    "> ### Embed Methods\n",
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-feature-selection-methods-online-ds-pt-100719/master/images/new_embedded.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTIVITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Rewrite Feature Selection Methods Lesson to easily capture and compare results across methods.**](https://learn.co/tracks/module-3-data-science-career-2-1/machine-learning/section-24-feature-selection-ridge-and-lasso/feature-selection-methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:35.218265Z",
     "start_time": "2020-03-19T22:26:34.990487Z"
    }
   },
   "outputs": [],
   "source": [
    "## Feature Selection Dataset\n",
    "data= \"https://raw.githubusercontent.com/learn-co-students/dsc-feature-selection-methods-online-ds-pt-100719/master/diabetes.tab.txt\"\n",
    "df = pd.read_csv(data,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:26:35.222211Z",
     "start_time": "2020-03-19T22:26:35.219659Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a new version of make_model that also adds a note column to results\n",
    "def run_model(model,X_train,X_test,y_train,y_test,note=''):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:50.367200Z",
     "start_time": "2020-03-19T22:31:50.350179Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Obtain the target and features from the DataFrame\n",
    "target = df['Y']\n",
    "features = df.drop(columns='Y')\n",
    "\n",
    "# Create dummy variable for sex\n",
    "features['female'] = pd.get_dummies(features['SEX'], drop_first=True)\n",
    "features.drop(columns=['SEX'], inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:51.331774Z",
     "start_time": "2020-03-19T22:31:51.310383Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=20, test_size=0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:52.090258Z",
     "start_time": "2020-03-19T22:31:52.085321Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "# Scale every feature except the binary column - female\n",
    "scale_cols = X_train.drop('female',axis=1).columns\n",
    "scale_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:52.861823Z",
     "start_time": "2020-03-19T22:31:52.847628Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
    "X_test[scale_cols] = scaler.transform(X_test[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:53.392160Z",
     "start_time": "2020-03-19T22:31:53.380931Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make an empty RESULTS list\n",
    "RESULTS = []\n",
    "## Run our baseline regression and append to RESULTS\n",
    "RESULTS.append(run_model(LinearRegression(),\n",
    "                         X_train,X_test,y_train,y_test,'Baseline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:53.901288Z",
     "start_time": "2020-03-19T22:31:53.889351Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_results(RESULTS,style_kws={'subset':['R2']}):\n",
    "    res = pd.concat(RESULTS).set_index('Note').groupby(\"Data\").get_group('Test')   \n",
    "    try:\n",
    "        display(res.style.background_gradient(**style_kws))\n",
    "    except:\n",
    "        display(res)\n",
    "show_results(RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:54.492975Z",
     "start_time": "2020-03-19T22:31:54.465426Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "\n",
    "X_poly_train = pd.DataFrame(poly.fit_transform(X_train),\n",
    "                            columns=poly.get_feature_names(features.columns))\n",
    "\n",
    "X_poly_test = pd.DataFrame(poly.transform(X_test),\n",
    "                           columns=poly.get_feature_names(features.columns))\n",
    "\n",
    "X_poly_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:55.015328Z",
     "start_time": "2020-03-19T22:31:55.002589Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make a linear regression with our X_poly data and append to RESULTS\n",
    "RESULTS.append(run_model(LinearRegression(),\n",
    "                         X_poly_train,X_poly_test,y_train,y_test,'Poly'))\n",
    "\n",
    "## Show resuls\n",
    "show_results(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"The benefit of filter methods is that they can provide us with some useful visualizations for helping us gain an understanding about the characteristics of our data. To begin with, let's use a simple variance threshold to eliminate the features with low variance.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:57.271892Z",
     "start_time": "2020-03-19T22:31:57.185312Z"
    }
   },
   "outputs": [],
   "source": [
    "## Filter Methods\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "threshold_ranges = np.linspace(0, 2, num=6)\n",
    "\n",
    "results = []\n",
    "for thresh in threshold_ranges:\n",
    "#     print(thresh)\n",
    "    selector = VarianceThreshold(thresh)\n",
    "    reduced_feature_train = selector.fit_transform(X_poly_train)\n",
    "    reduced_feature_test = selector.transform(X_poly_test)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(reduced_feature_train, y_train)\n",
    "    res = run_model(lr, reduced_feature_train, reduced_feature_test,\n",
    "                    y_train, y_test,f\"VarThresh={round(thresh,3)}\")\n",
    "    \n",
    "    results.append(res)\n",
    "\n",
    "res_df = pd.concat(results)\n",
    "RESULTS.append(res_df)\n",
    "show_results(RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Well, that did not seem to eliminate the features very well. It only does a little better than the base polynomial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:58.104859Z",
     "start_time": "2020-03-19T22:31:58.089309Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression, mutual_info_regression, SelectKBest\n",
    "selector = SelectKBest(score_func=f_regression)\n",
    "X_k_best_train = selector.fit_transform(X_poly_train, y_train)\n",
    "X_k_best_test= selector.transform(X_poly_test)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_k_best_train ,y_train)\n",
    "RESULTS.append(run_model(lr,X_k_best_train,X_k_best_test,y_train,y_test,'KBest-f_regr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:58.677701Z",
     "start_time": "2020-03-19T22:31:58.386888Z"
    }
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=mutual_info_regression)\n",
    "X_k_best_train = selector.fit_transform(X_poly_train, y_train)\n",
    "X_k_best_test= selector.transform(X_poly_test)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_k_best_train ,y_train)\n",
    "RESULTS.append(run_model(lr,X_k_best_train,X_k_best_test,y_train,y_test,'KBest-mutual_info'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Well, that did not seem to eliminate the features very well. It only does a little better than the base polynomial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper methods\n",
    "\n",
    "> Now let's use Recursive Feature elimination (RFE) to try out a wrapper method. You'll notice that scikit-learn has a built in `RFECV()` function, which automatically determines the optimal number of features to keep when it is run based off the estimator that is passed into it. Here it is in action: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:31:59.766776Z",
     "start_time": "2020-03-19T22:31:59.286520Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "rfe = RFECV(LinearRegression(),cv=5)\n",
    "X_rfe_train = rfe.fit_transform(X_poly_train, y_train)\n",
    "X_rfe_test = rfe.transform(X_poly_test)\n",
    "lm = LinearRegression().fit(X_rfe_train, y_train)\n",
    "RESULTS.append(run_model(lm, X_rfe_train, X_rfe_test, y_train, y_test,f'RFE w. {rfe.n_features_} feats'))\n",
    "# print ('The optimal number of features is: ', rfe.n_features_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded methods  \n",
    "> To compare to our other methods, we will use Lasso as the embedded method of feature selection. Luckily for us, sklearn has a built-in method to help us find the optimal features! It performs cross validation to determine the correct regularization parameter (how much to penalize our function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:32:00.102135Z",
     "start_time": "2020-03-19T22:31:59.967532Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso = LassoCV(max_iter=100000, cv=5)\n",
    "lasso.fit(X_train, y_train)\n",
    "RESULTS.append(run_model(lasso,X_train, X_test, y_train, y_test,f'Lasso w. a={lasso.alpha_}'))\n",
    "# print('The optimal alpha for the Lasso Regression is: ', lasso.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's compare this to a model with all of the polynomial features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:32:01.453891Z",
     "start_time": "2020-03-19T22:32:00.872835Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso2 = LassoCV(max_iter=100000, cv=5)\n",
    "lasso2.fit(X_poly_train, y_train)\n",
    "\n",
    "RESULTS.append(run_model(lasso2, X_poly_train, X_poly_test, y_train, y_test,f'Lasso Poly w. a={lasso2.alpha_}'))\n",
    "# print('The optimal alpha for the Lasso Regression is: ', lasso2.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:32:05.795288Z",
     "start_time": "2020-03-19T22:32:05.775359Z"
    }
   },
   "outputs": [],
   "source": [
    "show_results(RESULTS,style_kws=dict(subset=['RMSE'],\n",
    "                                   cmap = plt.cm.get_cmap('Greens').reversed()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T22:32:09.509197Z",
     "start_time": "2020-03-19T22:32:09.441501Z"
    }
   },
   "outputs": [],
   "source": [
    "res_df = pd.concat(RESULTS)\n",
    "res_df.set_index(['Note','Data']).style.highlight_min('RMSE')#.sort_values('MSE',ascending=True)#.groupby('Data').get_group('Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As we can see, the regularization had minimal effect on the performance of the model, but it did improve the RMSE for the test set ever so slightly! There are no set steps someone should take in order to determine the optimal feature set. In fact, now there are automated machine learning pipelines that will determine the optimal subset of features for a given problem. One of the most important and often overlooked methods of feature selection is using domain knowledge about a given area to either eliminate features or create new ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
